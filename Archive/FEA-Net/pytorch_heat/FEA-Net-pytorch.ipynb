{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:12:37.978677Z",
     "start_time": "2018-12-18T11:12:37.976016Z"
    }
   },
   "source": [
    "This is the PyTorch version of FEA-net rewritten from Houpu's TensorFlow code.\n",
    "\n",
    "Note that only the elasticity problems are implemented (not implement yet).\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T11:10:53.160742Z",
     "start_time": "2018-12-30T11:10:51.404495Z"
    },
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img):\n",
    "    img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticDataset(Dataset):\n",
    "    \"\"\" Currently only support import one loading case with noise precent \"\"\"\n",
    "    def __init__(self, datafile, percent=0.0):\n",
    "        data = sio.loadmat(datafile)\n",
    "        load = np.stack([-data['fx']/1e6, -data['fy']/1e6], 0).astype('float32')\n",
    "        resp = np.stack([data['ux']*1e6, data['uy']*1e6], 0).astype('float32')\n",
    "        \n",
    "        # convert to PyTorch tensor\n",
    "        self.load = torch.from_numpy(load)\n",
    "        self.resp = torch.from_numpy(resp)\n",
    "        \n",
    "        # add some noises\n",
    "        self.percent = percent\n",
    "        noise = self.percent * np.random.normal(size=self.load.shape)\n",
    "        self.loading_w_noise = torch.from_numpy((1+noise) * load)\n",
    "        noise = self.percent * np.random.normal(size=self.load.shape)\n",
    "        self.response_w_noise = torch.from_numpy((1+noise) * resp)\n",
    "\n",
    "        # material property: E, mu\n",
    "        self.rho = [212e3, 0.288] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.load.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data = {'num_node': self.load.shape[1],\n",
    "                'rho': self.rho,\n",
    "                'train_load': self.loading_w_noise,\n",
    "                'train_resp': self.response_w_noise,\n",
    "                'test_load': self.load,\n",
    "                'test_resp': self.resp,\n",
    "                } \n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = ElasticDataset('../data/elasticity/center_crack_36x36_xy.mat', percent=0.001)\n",
    "data_loader = DataLoader(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def apply_n_times(f, n):\n",
    "    \"\"\"Returns a new function which is f folded n times: f(f(f(f(...f(f(n))...))))\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "\n",
    "    apply_n_times(lambda x: x**2, 3)(2) == 256\n",
    "    \"\"\"\n",
    "\n",
    "    def f_folded_n_times(x):\n",
    "        return reduce(lambda fx, _: f(fx), range(n), x)\n",
    "    return f_folded_n_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jacobi_block():\n",
    "    def __init__(self, data, cfg):\n",
    "        self.batch_size = 1 # only use 1 training example\n",
    "        self.num_node = data['num_node']\n",
    "        self.E, self.mu, self.k, self.alpha = self.rho = data['rho']\n",
    "        self.set_bc()\n",
    "\n",
    "    def set_bc(self):\n",
    "        ''' bc_mask: 1.0 for inner points, 0.0 elsewhere '''\n",
    "        ''' bc_values: assign values for boundary points, 0.0 elsewhere '''\n",
    "        self.bc_mask = np.ones((self.batch_size, 1, self.num_node, self.num_node))\n",
    "        self.bc_mask[:, :, 0, :] = 0\n",
    "        self.bc_mask[:, :, -1, :] = 0\n",
    "        self.bc_mask[:, :, :, 0] = 0\n",
    "        self.bc_mask[:, :, :, -1] = 0\n",
    "        self.bc_values = np.zeros((self.batch_size, 1, self.num_node, self.num_node))\n",
    "        \n",
    "    def boundary_padding(self,x):\n",
    "        ''' special symmetric boundary padding: mirror filling '''\n",
    "        ''' x is a 2D pytorch tensor '''\n",
    "        pad = torch.nn.ReflectionPad2d(padding=1)\n",
    "        padded_x = pad(x)\n",
    "        return padded_x\n",
    "\n",
    "    def iter_step(self, u_in):\n",
    "        self.FEA_conv = torch.nn.Conv2d(2, 4, 3, padding='valid')\n",
    "        self.FEA_conv.weight = torch.nn.Parameter\n",
    "\n",
    "        for param in self.FEA_conv.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        u_in = self.FEA_conv(u_in) * self.bc_mask + self.bc_values\n",
    "\n",
    "    def apply(self, u0, max_itr=10):\n",
    "        ''' u0 is the initial displacement values '''\n",
    "        if u0 is None:\n",
    "            u = torch.zeros(self.batch_size, 1, self.num_node, self.num_node)\n",
    "        else:\n",
    "            u = u0\n",
    "        \n",
    "        padded_u = self.boundary_padding(u)\n",
    "             \n",
    "\n",
    "    def get_matrix_elast(self):\n",
    "        ''' Shape of pytorch filters: (output channel, input channel, size, size) '''\n",
    "        ''' Input channel: 2=Ux,Uy; Output channel: 4=Vxx,Vxy,Vyx,Vyy '''\n",
    "        E, mu = self.E, self.mu\n",
    "        cost_coef = E / 16. / (1 - mu ** 2)\n",
    "        self.wxx = cost_coef * np.asarray([\n",
    "            [-4 * (1 - mu / 3.), 16 * mu / 3., -4 * (1 - mu / 3.)],\n",
    "            [-8 * (1 + mu / 3.), 32. * (1 - mu / 3.), -8 * (1 + mu / 3.)],\n",
    "            [-4 * (1 - mu / 3.), 16 * mu / 3., -4 * (1 - mu / 3.)],\n",
    "        ], dtype='float32').reshape(1,1,3,3)\n",
    "\n",
    "        self.wxy = cost_coef * np.asarray([\n",
    "            [2 * (mu + 1), 0, -2 * (mu + 1)],\n",
    "            [0, 0, 0],\n",
    "            [-2 * (mu + 1), 0, 2 * (mu + 1)],\n",
    "        ], dtype='float32').reshape(1,1,3,3)\n",
    "\n",
    "        self.wyx = cost_coef * np.asarray([\n",
    "            [2 * (mu + 1), 0, -2 * (mu + 1)],\n",
    "            [0, 0, 0],\n",
    "            [-2 * (mu + 1), 0, 2 * (mu + 1)],\n",
    "        ], dtype='float32').reshape(1,1,3,3)\n",
    "\n",
    "        self.wyy = cost_coef * np.asarray([\n",
    "            [-4 * (1 - mu / 3.), -8 * (1 + mu / 3.), -4 * (1 - mu / 3.)],\n",
    "            [16 * mu / 3., 32. * (1 - mu / 3.), 16 * mu / 3.],\n",
    "            [-4 * (1 - mu / 3.), -8 * (1 + mu / 3.), -4 * (1 - mu / 3.)],\n",
    "        ], dtype='float32').reshape(1,1,3,3)\n",
    "\n",
    "        self.d_matrix = np.stack([self.wxx[0,0,1,1], self.wyy[0,0,1,1], 1])  # diagonal matrix containing x, y components\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.009\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a jacobi network\n",
    "\n",
    "# inverse generative\n",
    "#   forward_pass(resp_pl)\n",
    "#   tf.reduce_mean()\n",
    "#   pred_err\n",
    "#   get_optimizer()\n",
    "#       AdamOptimizer(lr = 0.1, beta1 = 0.5)\n",
    "#   train epoh\n",
    "\n",
    "# forward solving\n",
    "#   jacobi.apply()\n",
    "#       max_itr = 10\n",
    "#   get_loss()\n",
    "#   get_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEA_Net_h():\n",
    "    # NOTICE: right now for homogeneous anisotropic material only!!\n",
    "    def __init__(self, data, cfg):\n",
    "        # set learning rate\n",
    "        self.lr = cfg['lr']\n",
    "        self.num_epoch = cfg['epoch']\n",
    "\n",
    "        # data related\n",
    "        self.num_node = data['num_node']\n",
    "        self.E, self.mu, self.k, self.alpha = self.rho = data['rho'] \n",
    "\n",
    "        # 3 dimensional in and out, defined on the nodes\n",
    "        self.load_pl = tf.placeholder(tf.float32, shape=(None, data['num_node'], data['num_node'], 3), name='load_pl')\n",
    "        self.resp_pl = tf.placeholder(tf.float32, shape=(None, data['num_node'], data['num_node'], 3), name='resp_pl')\n",
    "\n",
    "        # get filters\n",
    "        self.get_w_matrix()\n",
    "        self.load_pred = self.u2v_map()\n",
    "\n",
    "\n",
    "    def get_w_matrix(self):\n",
    "        self.get_w_matrix_elast()\n",
    "        self.get_w_matrix_thermal()\n",
    "        self.get_w_matrix_coupling()\n",
    "        self.apply_physics_constrain()\n",
    "\n",
    "    def apply_physics_constrain(self):\n",
    "        # known physics\n",
    "        self.wxx_tf = tf.constant(self.wxx_ref)\n",
    "        self.wyy_tf = tf.constant(self.wyy_ref)\n",
    "        self.wxy_tf = tf.constant(self.wxy_ref)\n",
    "        self.wyx_tf = tf.constant(self.wyx_ref)\n",
    "        self.wtt_tf = tf.constant(self.wtt_ref)\n",
    "        self.wtx_tf = tf.constant(self.wtx_ref)\n",
    "        self.wty_tf = tf.constant(self.wty_ref)\n",
    "\n",
    "        # unknown physics\n",
    "        self.wxt_np = np.zeros_like(self.wxt_ref)  # * 1.9\n",
    "        self.wyt_np = np.zeros_like(self.wyt_ref)  # * 1.9\n",
    "\n",
    "        # TF variable vector\n",
    "        self.trainable_var_np = np.concatenate([self.wxt_np.flatten(),\n",
    "                                                self.wyt_np.flatten()], 0)\n",
    "        self.trainable_var_ref = np.concatenate([self.wxt_ref.flatten(),\n",
    "                                                self.wyt_ref.flatten()], 0)\n",
    "        self.trainable_var_pl = tf.placeholder(tf.float32, shape=(9 * 2,), name='filter_vector')\n",
    "\n",
    "        wxt_tf, wyt_tf = tf.split(self.trainable_var_pl, 2)\n",
    "        self.wxt_tf = tf.reshape(wxt_tf, (3, 3, 1, 1))\n",
    "        self.wyt_tf = tf.reshape(wyt_tf, (3, 3, 1, 1))\n",
    "\n",
    "        # add constrains\n",
    "        self.singula_penalty = (tf.reduce_sum(self.wxt_tf)\n",
    "                              + tf.reduce_sum(self.wyt_tf)\n",
    "                                )**2\n",
    "        # self.E = tf.clip_by_value(self.E, 0, 1)\n",
    "        # self.mu = tf.clip_by_value(self.mu, 0, 0.5)\n",
    "\n",
    "        # tf.nn.conv2d filter shape: [filter_height, filter_width, in_channels, out_channels]\n",
    "        self.w_filter = tf.concat([tf.concat([self.wxx_tf, self.wxy_tf, self.wxt_tf], 2),\n",
    "                                   tf.concat([self.wyx_tf, self.wyy_tf, self.wyt_tf], 2),\n",
    "                                   tf.concat([self.wtx_tf, self.wty_tf, self.wtt_tf], 2)],\n",
    "                                  3)\n",
    "\n",
    "        self.w_filter_ref = np.concatenate([np.concatenate([self.wxx_ref, self.wxy_ref, self.wxt_ref], 2),\n",
    "                                   np.concatenate([self.wyx_ref, self.wyy_ref, self.wyt_ref], 2),\n",
    "                                   np.concatenate([self.wtx_ref, self.wty_ref, self.wtt_ref], 2)],\n",
    "                                  3)\n",
    "\n",
    "    def get_w_matrix_coupling(self):\n",
    "        E, v = self.E, self.mu\n",
    "        alpha = self.alpha\n",
    "        self.wtx_ref = np.zeros((3,3,1,1), dtype='float32')\n",
    "        self.wty_ref = np.zeros((3,3,1,1), dtype='float32')\n",
    "        coef = E * alpha / (6*(v-1)) / 400 *1e6\n",
    "        self.wxt_ref = coef * np.asarray([[1, 0, -1],\n",
    "                                      [4, 0, -4],\n",
    "                                      [1, 0, -1]]\n",
    "                                     , dtype='float32').reshape(3,3,1,1)\n",
    "\n",
    "        self.wyt_ref = coef * np.asarray([[-1, -4, -1],\n",
    "                                      [0, 0, 0],\n",
    "                                      [1, 4, 1]]\n",
    "                                     , dtype='float32').reshape(3,3,1,1)\n",
    "\n",
    "    def get_w_matrix_thermal(self):\n",
    "        w = -1/3. * self.k * np.asarray([[1., 1., 1.], [1., -8., 1.], [1., 1., 1.]])\n",
    "        w = np.asarray(w, dtype='float32')\n",
    "        self.wtt_ref = w.reshape(3,3,1,1)\n",
    "\n",
    "    def get_w_matrix_elast(self):\n",
    "        E, mu = self.E, self.mu\n",
    "        cost_coef = E / 16. / (1 - mu ** 2)\n",
    "        wxx = cost_coef * np.asarray([\n",
    "            [-4 * (1 - mu / 3.), 16 * mu / 3., -4 * (1 - mu / 3.)],\n",
    "            [-8 * (1 + mu / 3.), 32. * (1 - mu / 3.), -8 * (1 + mu / 3.)],\n",
    "            [-4 * (1 - mu / 3.), 16 * mu / 3., -4 * (1 - mu / 3.)],\n",
    "        ], dtype='float32')\n",
    "\n",
    "        wxy = wyx = cost_coef * np.asarray([\n",
    "            [2 * (mu + 1), 0, -2 * (mu + 1)],\n",
    "            [0, 0, 0],\n",
    "            [-2 * (mu + 1), 0, 2 * (mu + 1)],\n",
    "        ], dtype='float32')\n",
    "\n",
    "        wyy = cost_coef * np.asarray([\n",
    "            [-4 * (1 - mu / 3.), -8 * (1 + mu / 3.), -4 * (1 - mu / 3.)],\n",
    "            [16 * mu / 3., 32. * (1 - mu / 3.), 16 * mu / 3.],\n",
    "            [-4 * (1 - mu / 3.), -8 * (1 + mu / 3.), -4 * (1 - mu / 3.)],\n",
    "        ], dtype='float32')\n",
    "\n",
    "        self.wxx_ref = wxx.reshape(3,3,1,1)\n",
    "        self.wxy_ref = wxy.reshape(3,3,1,1)\n",
    "        self.wyx_ref = wyx.reshape(3,3,1,1)\n",
    "        self.wyy_ref = wyy.reshape(3,3,1,1)\n",
    "\n",
    "    def boundary_padding(self,x):\n",
    "        ''' special symmetric boundary padding '''\n",
    "        left = x[:, :, 1:2, :]\n",
    "        right = x[:, :, -2:-1, :]\n",
    "        upper = tf.concat([x[:, 1:2, 1:2, :], x[:, 1:2, :, :], x[:, 1:2, -2:-1, :]], 2)\n",
    "        down = tf.concat([x[:, -2:-1, 1:2, :], x[:, -2:-1, :, :], x[:, -2:-1, -2:-1, :]], 2)\n",
    "        padded_x = tf.concat([left, x, right], 2)\n",
    "        padded_x = tf.concat([upper, padded_x, down], 1)\n",
    "        return padded_x\n",
    "\n",
    "    def u2v_map(self):\n",
    "        padded_resp = self.boundary_padding(self.resp_pl)  # for boundary consideration\n",
    "        wx = tf.nn.conv2d(input=padded_resp, filter=self.w_filter, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        return wx\n",
    "\n",
    "    def get_loss(self):\n",
    "        self.diff = self.load_pred - self.load_pl\n",
    "        diff_not_on_bc = self.apply_bc(self.diff)\n",
    "        self.l1_error = tf.reduce_mean(diff_not_on_bc**2)\n",
    "        # self.l1_error = tf.reduce_mean((self.diff_not_on_bc*self.resp_pl[:,1:-1,1:-1,:])**2)\n",
    "        self.loss = self.l1_error #+ self.singula_penalty\n",
    "        return self.loss\n",
    "\n",
    "    def get_grad(self):\n",
    "        self.rho_grads = tf.gradients(self.loss, self.trainable_var_pl)\n",
    "        return self.rho_grads\n",
    "\n",
    "    def get_hessian(self):\n",
    "        self.rho_hessian = tf.hessians(self.loss, self.trainable_var_pl)\n",
    "        return self.rho_hessian\n",
    "\n",
    "    # V2U mapping functions\n",
    "    def apply_bc(self, x):\n",
    "        x_bc = tf.pad(x[:, 1:-1, 1:-1, :], ((0,0), (1, 1),(1, 1), (0, 0)), \"constant\")  # for boundary consideration\n",
    "        return x_bc\n",
    "\n",
    "    def FEA_conv(self, w, x):\n",
    "        padded_input = self.boundary_padding(x)  # for boundary consideration\n",
    "        wx = tf.nn.conv2d(input=padded_input, filter=w, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        wx_bc = wx * self.bc_mask # boundary_corrrect\n",
    "        return wx_bc\n",
    "\n",
    "    def v2u_layer(self, w, x):\n",
    "        wx = self.FEA_conv(w, x)\n",
    "        wx_bc = self.apply_bc(wx)\n",
    "        return wx_bc\n",
    "\n",
    "    def get_dmat(self):\n",
    "        d_matrix = tf.stack([self.wxx_tf[1,1,0,0], self.wyy_tf[1,1,0,0], self.wtt_tf[1,1,0,0]])  # x, y, and t components\n",
    "        return tf.reshape(d_matrix,(1,1,1,3))\n",
    "\n",
    "    def get_bc_mask(self):\n",
    "        bc_mask = np.ones_like(self.new_load)\n",
    "        bc_mask[:, 0, :, :] /= 2\n",
    "        bc_mask[:, -1, :, :] /= 2\n",
    "        bc_mask[:, :, 0, :] /= 2\n",
    "        bc_mask[:, :, -1, :] /= 2\n",
    "        return bc_mask\n",
    "\n",
    "    def init_solve(self, load, omega):\n",
    "        self.omega = omega\n",
    "        self.new_load = load\n",
    "        self.d_matrix = self.get_dmat()\n",
    "        self.bc_mask = self.get_bc_mask()\n",
    "        self.u_in = tf.placeholder(tf.float32, load.shape, name='u_in')\n",
    "        self.u_out = self.apply(self.u_in)\n",
    "\n",
    "    def apply(self, u_in):\n",
    "        wx = self.v2u_layer(self.w_filter, u_in)\n",
    "        u_out = self.omega * (self.new_load - wx) / self.d_matrix +  u_in\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, model, data):\n",
    "        self.model = model\n",
    "\n",
    "        self.data = data\n",
    "        self.init_w = np.zeros((3,3,1,1))\n",
    "\n",
    "        self.loss_value = None\n",
    "        self.grads_value = None\n",
    "\n",
    "        self.loss_tf = self.model.get_loss()\n",
    "        self.hessian_tf = self.model.get_hessian()\n",
    "        self.grad_tf = self.model.get_grad()\n",
    "        self.initial_graph()\n",
    "\n",
    "    def initial_graph(self):\n",
    "        # initialize\n",
    "        FLAGS = tf.app.flags.FLAGS\n",
    "        tfconfig = tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=True,\n",
    "        )\n",
    "        tfconfig.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=tfconfig)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def get_loss(self, w):\n",
    "        self.feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                          self.model.resp_pl: data['train_resp'],\n",
    "                          self.model.trainable_var_pl: w}\n",
    "        self.loss_value = self.sess.run(self.loss_tf, self.feed_dict).astype('float64')\n",
    "        return self.loss_value\n",
    "\n",
    "    def get_grads(self, w):\n",
    "        self.feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                          self.model.resp_pl: data['train_resp'],\n",
    "                          self.model.trainable_var_pl: w}\n",
    "        self.grads_value = self.sess.run(self.grad_tf, self.feed_dict)[0].flatten().astype('float64')\n",
    "        return self.grads_value\n",
    "\n",
    "    def get_hessian(self, w):\n",
    "        self.feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                          self.model.resp_pl: data['train_resp'],\n",
    "                          self.model.trainable_var_pl: w}\n",
    "        self.hessian_value = self.sess.run(self.hessian_tf, self.feed_dict)[0].astype('float64')\n",
    "        return self.hessian_value\n",
    "\n",
    "    def get_pred(self,w):\n",
    "        feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                      self.model.resp_pl: data['train_resp'],\n",
    "                      self.model.trainable_var_pl: w.astype('float32')}\n",
    "        pred_value = self.sess.run(self.model.load_pred, feed_dict)\n",
    "        return pred_value\n",
    "\n",
    "    def run_newton(self):\n",
    "        from scipy.optimize import minimize\n",
    "        self.result = minimize(self.get_loss, self.model.trainable_var_np, method='Newton-CG',\n",
    "                          jac=self.get_grads, hess=self.get_hessian,\n",
    "                          options={'xtol': 1e-8, 'disp': True})\n",
    "        return self.result.x\n",
    "\n",
    "    def visualize(self, w):\n",
    "        pred_value = self.get_pred(w)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        idx = 0  # which data to visualize\n",
    "        for i in range(3):\n",
    "            plt.subplot(4, 3, i + 1)\n",
    "            plt.imshow(self.data['test_resp'][idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "            plt.subplot(4, 3, 3 + i + 1)\n",
    "            plt.imshow(self.data['test_load'][idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "            plt.subplot(4, 3, 6 + i + 1)\n",
    "            plt.imshow(pred_value[idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "            plt.subplot(4, 3, 9 + i + 1)\n",
    "            plt.imshow(self.data['test_load'][idx, 1:-1, 1:-1, i] - pred_value[idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def init_solve(self, load, omega=2/3.):\n",
    "        self.model.init_solve(load, omega)\n",
    "        self.solution = {'itr':[], 'loss': [], 'pred':[]}\n",
    "\n",
    "    def run_forward(self, filter, pred_i, resp_ref=None, max_itr=100):\n",
    "\n",
    "        st = 0 if self.solution['itr'] == [] else self.solution['itr'][-1]+10\n",
    "        for itr in tqdm(range(st, st+max_itr, 1)):\n",
    "            feed_dict = {self.model.u_in: pred_i, self.model.trainable_var_pl:filter}\n",
    "            pred_i = self.sess.run(self.model.u_out, feed_dict)\n",
    "            if itr%1 == 0:\n",
    "                self.solution['itr'] += [itr]\n",
    "                self.solution['pred'] += [pred_i]\n",
    "                if resp_ref is not None:\n",
    "                    pred_err_i = np.sqrt(np.sum((resp_ref - pred_i) ** 2)) / np.sqrt(  np.sum((resp_ref) ** 2))\n",
    "                    print(\"iter:{}  pred_err: {}\".format(itr, np.mean(pred_err_i)))\n",
    "                    self.solution['loss'] += [np.mean(pred_err_i)]\n",
    "\n",
    "        return pred_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(percent=0.1)#snr=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'lr': 0.001,\n",
    "        'epoch': 1,\n",
    "        }\n",
    "model = FEA_Net_h(data,cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model, data)\n",
    "result = evaluator.run_newton()#run_trust_ncg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.visualize(result)\n",
    "for i in range(2):\n",
    "    mat = result[9*i:9*(i+1)]\n",
    "    print(mat.reshape(3,3))\n",
    "    print(np.sum(mat))\n",
    "print(model.wxt_ref.reshape(3,3))\n",
    "print(np.sum(model.wxt_ref))\n",
    "print(model.wyt_ref.reshape(3,3))\n",
    "print(np.sum(model.wyt_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.init_solve(load=data['test_load'], omega=2/3.)\n",
    "pred_i = np.zeros_like(data['test_resp'])  # data['test_resp']#\n",
    "resp_ref = data['test_resp']\n",
    "pred_i = evaluator.run_forward(model.trainable_var_ref, pred_i, resp_ref, max_itr=4000)\n",
    "s0 = evaluator.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.init_solve(load=data['test_load'], omega=2/3.)\n",
    "pred_i = np.zeros_like(data['test_resp'])  # data['test_resp']#\n",
    "pred_i = evaluator.run_forward(result, pred_i, resp_ref, max_itr=4000)\n",
    "s1 = evaluator.solution\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(s0['itr'], s0['loss'], label='ref')\n",
    "plt.semilogy(s1['itr'], s1['loss'], label='pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "name": "main.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "67.7px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "584.933px",
    "left": "1px",
    "right": "2569px",
    "top": "111px",
    "width": "600px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
