{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for the paper Learning to optimize multigrid PDE solvers, which can be found on https://arxiv.org/abs/1902.10248. \n",
    "\n",
    "The notation of the grid points is as follows: in any grid-related tensor, the (0,0) cell corresponds to the leftmost bottommost grid cell. The (I,J) cell then corresponds to the grid cell located in the I'th column and J'th row of the grid.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal function\n",
    "def extend_hierarchy(levels, prolongation_fn, prolongation_args):\n",
    "    \"\"\"Extend the multigrid hierarchy.\"\"\"\n",
    "\n",
    "    A = levels[-1].A\n",
    "\n",
    "    # Generate the interpolation matrix that maps from the coarse-grid to the\n",
    "    # fine-grid\n",
    "    P = prolongation_fn(A, prolongation_args)\n",
    "\n",
    "    # Generate the restriction matrix that maps from the fine-grid to the\n",
    "    # coarse-grid\n",
    "    R = P.T.tocsr()\n",
    "\n",
    "    levels[-1].P = P  # prolongation operator\n",
    "    levels[-1].R = R  # restriction operator\n",
    "\n",
    "    levels.append(multilevel_solver.level())\n",
    "\n",
    "    # Form next level through Galerkin product\n",
    "    A = R * A * P\n",
    "    A = A.astype(np.float64)  # convert from complex numbers, should have A.imag==0\n",
    "    levels[-1].A = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to \"ruge_stuben_solver\" in pyamg\n",
    "def geometric_solver(A, prolongation_function, prolongation_args,\n",
    "                     presmoother=('gauss_seidel', {'sweep': 'forward'}),\n",
    "                     postsmoother=('gauss_seidel', {'sweep': 'forward'}),\n",
    "                     max_levels=10, max_coarse=10, **kwargs):\n",
    "    \"\"\"Create a multilevel solver using geometric AMG.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : csr_matrix\n",
    "        Square matrix in CSR format\n",
    "    presmoother : string or dict\n",
    "        Method used for presmoothing at each level.  Method-specific parameters\n",
    "        may be passed in using a tuple, e.g.\n",
    "        presmoother=('gauss_seidel',{'sweep':'symmetric}), the default.\n",
    "    postsmoother : string or dict\n",
    "        Postsmoothing method with the same usage as presmoother\n",
    "    max_levels: integer\n",
    "        Maximum number of levels to be used in the multilevel solver.\n",
    "    max_coarse: integer\n",
    "        Maximum number of variables permitted on the coarse grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ml : multilevel_solver\n",
    "        Multigrid hierarchy of matrices and prolongation operators\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    \"coarse_solver\" is an optional argument and is the solver used at the\n",
    "    coarsest grid.  The default is a pseudo-inverse.  Most simply,\n",
    "    coarse_solver can be one of ['splu', 'lu', 'cholesky, 'pinv',\n",
    "    'gauss_seidel', ... ].  Additionally, coarse_solver may be a tuple\n",
    "    (fn, args), where fn is a string such as ['splu', 'lu', ...] or a callable\n",
    "    function, and args is a dictionary of arguments to be passed to fn.\n",
    "    See [2001TrOoSc]_ for additional details.\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [2001TrOoSc] Trottenberg, U., Oosterlee, C. W., and Schuller, A.,\n",
    "       \"Multigrid\" San Diego: Academic Press, 2001.  Appendix A\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    aggregation.smoothed_aggregation_solver, multilevel_solver,\n",
    "    aggregation.rootnode_solver\n",
    "\n",
    "    \"\"\"\n",
    "    levels = [multilevel_solver.level()]\n",
    "\n",
    "    # convert A to csr\n",
    "    if not isspmatrix_csr(A):\n",
    "        try:\n",
    "            A = csr_matrix(A)\n",
    "            warn(\"Implicit conversion of A to CSR\",\n",
    "                 SparseEfficiencyWarning)\n",
    "        except BaseException:\n",
    "            raise TypeError('Argument A must have type csr_matrix, \\\n",
    "                             or be convertible to csr_matrix')\n",
    "    # preprocess A\n",
    "    A = A.asfptype()\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        raise ValueError('expected square matrix')\n",
    "\n",
    "    levels[-1].A = A\n",
    "\n",
    "    while len(levels) < max_levels and levels[-1].A.shape[0] > max_coarse:\n",
    "        extend_hierarchy(levels, prolongation_function, prolongation_args)\n",
    "\n",
    "    ml = multilevel_solver(levels, **kwargs)\n",
    "    change_smoothers(ml, presmoother, postsmoother)\n",
    "    return ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def compute_p2(self, P_stencil, grid_size):\n",
    "        indexes = self.get_p_matrix_indices_one(grid_size)\n",
    "        P = csr_matrix(arg1=(P_stencil.numpy().reshape(-1), (indexes[:, 0], indexes[:, 1])),\n",
    "                       shape=(grid_size ** 2, (grid_size // 2) ** 2))\n",
    "\n",
    "        return P\n",
    "        \n",
    "    @memoize\n",
    "    def compute_A_indices(self, grid_size):\n",
    "        K = self.map_2_to_1(grid_size=grid_size)\n",
    "        A_idx = []\n",
    "        stencil_idx = []\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                I = int(K[i, j, 1, 1])\n",
    "                for k in range(3):\n",
    "                    for m in range(3):\n",
    "                        J = int(K[i, j, k, m])\n",
    "                        A_idx.append([I, J])\n",
    "                        stencil_idx.append([i, j, k, m])\n",
    "        return np.array(A_idx), stencil_idx\n",
    "\n",
    "    def compute_csr_matrices(self, stencils, grid_size=8):\n",
    "        A_idx, stencil_idx = self.compute_A_indices(grid_size)\n",
    "        if len(stencils.shape) == 5:\n",
    "            matrices = []\n",
    "            for stencil in stencils:\n",
    "                matrices.append(csr_matrix(arg1=(stencil.reshape((-1)), (A_idx[:, 0], A_idx[:, 1])),\n",
    "                                           shape=(grid_size ** 2, grid_size ** 2)))\n",
    "            return np.asarray(matrices)\n",
    "        else:\n",
    "            return csr_matrix(arg1=(stencils.reshape((-1)), (A_idx[:, 0], A_idx[:, 1])),\n",
    "                              shape=(grid_size ** 2, grid_size ** 2))\n",
    "                              \n",
    "    def solve_with_model(self, model, A_matrices, b, initial_guess, max_iterations, max_depth=3, blackbox=False,\n",
    "                         w_cycle=False):\n",
    "        def prolongation_fn(A, args):\n",
    "            is_blackbox = args[\"is_blackbox\"]\n",
    "            grid_size = int(math.sqrt(A.shape[0]))\n",
    "            indices = self.get_indices_compute_A_one(grid_size)\n",
    "            A_stencil = np.array(A[indices[:, 0], indices[:, 1]]).reshape((grid_size, grid_size, 3, 3))\n",
    "            model.grid_size = grid_size  # TODO: infer grid_size automatically\n",
    "\n",
    "            tf_A_stencil = tf.convert_to_tensor([A_stencil])\n",
    "            with tf.device(self.device):\n",
    "                if is_blackbox:\n",
    "                    P_stencil = model(inputs=tf_A_stencil, black_box=True)\n",
    "                else:\n",
    "                    P_stencil = model(inputs=tf_A_stencil, black_box=False, phase=\"Test\")\n",
    "            return self.compute_p2(P_stencil, grid_size).astype(np.double)  # imaginary part should be zero\n",
    "\n",
    "        prolongation_args = {\"is_blackbox\": blackbox}\n",
    "\n",
    "        error_norms = []\n",
    "\n",
    "        #  solver calls this function after each iteration\n",
    "        def error_callback(x_k):\n",
    "            error_norms.append(pyamg.util.linalg.norm(x_k))\n",
    "\n",
    "        solver = geometric_solver(A_matrices, prolongation_fn, prolongation_args,\n",
    "                                  max_levels=max_depth)\n",
    "\n",
    "        if w_cycle:\n",
    "            cycle = 'W'\n",
    "        else:\n",
    "            cycle = 'V'\n",
    "        residual_norms = []\n",
    "        x = solver.solve(b, x0=initial_guess, maxiter=max_iterations, cycle=cycle, residuals=residual_norms, tol=0,\n",
    "                         callback=error_callback)\n",
    "        return x, residual_norms, error_norms, solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pnetwork(tf.keras.Model):\n",
    "    def __init__(self, grid_size=8, device=\"/cpu:0\"):\n",
    "        super(Pnetwork, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.device = device\n",
    "    \n",
    "    def call(self, inputs, black_box=False, index=None, pos=-1., phase='Training'):\n",
    "        # inputs are stencils\n",
    "        with tf.device(self.device):\n",
    "            if not black_box:\n",
    "                x = self.linear0(flattended)\n",
    "                x = tf.nn.relu(x)\n",
    "                for i in range(1, self.num_layers, 2):\n",
    "                    x1 = getattr(self, \"bias_1%i\" % i) + x\n",
    "                    x1 = getattr(self, \"linear%i\" % i)(x1)\n",
    "                    x1 = x1 + getattr(self, \"bias_2%i\" % i) + x1\n",
    "                    x1 = tf.nn.relu(x1)\n",
    "                    x1 = x1 + getattr(self, \"bias_3%i\" % i) + x1\n",
    "                    x1 = getattr(self, \"linear%i\" % (i + 1))(x1)\n",
    "                    x1 = tf.multiply(x1, getattr(self, \"multiplier_%i\" % i))\n",
    "                    x = x + x1\n",
    "                    x = x + getattr(self, \"bias_4%i\" % i)\n",
    "                    x = tf.nn.relu(x)\n",
    "\n",
    "                x = self.output_layer(x)\n",
    "                \n",
    "            if black_box:\n",
    "                up_contributions_output = tf.gather(inputs,[i for i in range(0,self.grid_size,2)],axis=1)\n",
    "                up_contributions_output = tf.gather(up_contributions_output,\n",
    "                                                    [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "                up_contributions_output = -tf.reduce_sum(up_contributions_output[:,:,:,:,0],axis=-1)/tf.reduce_sum(up_contributions_output[:,:,:,:,1],axis=-1)\n",
    "\n",
    "                left_contributions_output = tf.gather(inputs, idx, axis=1)\n",
    "                left_contributions_output = tf.gather(left_contributions_output,\n",
    "                                                      [i for i in range(0,self.grid_size,2)], axis=2)\n",
    "                left_contributions_output = -tf.reduce_sum(left_contributions_output[:, :, :, 2, :],\n",
    "                                                            axis=-1) / tf.reduce_sum(\n",
    "                    left_contributions_output[:, :, :, 1, :], axis=-1)\n",
    "\n",
    "                right_contributions_output = tf.gather(inputs, [i for i in range(1,self.grid_size,2)], axis=1)\n",
    "                right_contributions_output = tf.gather(right_contributions_output, [i for i in range(0,self.grid_size,2)], axis=2)\n",
    "                right_contributions_output = -tf.reduce_sum(right_contributions_output[:, :, :, 0, :],\n",
    "                                                           axis=-1) / tf.reduce_sum(\n",
    "                    right_contributions_output[:, :, :, 1, :], axis=-1)\n",
    "                down_contributions_output = tf.gather(inputs, [i for i in range(0,self.grid_size,2)], axis=1)\n",
    "                down_contributions_output = tf.gather(down_contributions_output, idx, axis=2)\n",
    "                down_contributions_output = -tf.reduce_sum(down_contributions_output[:, :, :, :, 2],\n",
    "                                                            axis=-1) / tf.reduce_sum(\n",
    "                    down_contributions_output[:, :, :, :, 1], axis=-1)\n",
    "            else:\n",
    "                jm1 = [(i - 1) % (self.grid_size // 2) for i in range(self.grid_size // 2)]\n",
    "                jp1 = [(i + 1) % (self.grid_size // 2) for i in range(self.grid_size // 2)]\n",
    "                right_contributions_output = x[:,:,:,0]/(tf.gather(x[:, :, :, 1],jp1,axis=1)+x[:,:,:,0])\n",
    "                left_contributions_output = x[:,:,:,1]/(x[:,:,:,1]+tf.gather(x[:, :, :, 0],jm1,axis=1))\n",
    "                up_contributions_output = x[:,:,:,2]/(x[:,:,:,2]+tf.gather(x[:, :, :, 3],jp1,axis=2))\n",
    "                down_contributions_output = x[:,:,:,3]/(tf.gather(x[:, :, :, 2],jm1,axis=2)+x[:,:,:,3])\n",
    "            ones = tf.ones_like(down_contributions_output)\n",
    "\n",
    "            #based on rule 2 given rule 1:\n",
    "            up_right_contribution = tf.gather(inputs,[i for i in range(1,self.grid_size,2)],axis=1)\n",
    "            up_right_contribution = tf.gather(up_right_contribution, [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "            up_right_contribution = up_right_contribution [:,:,:,0,1]\n",
    "            right_up_contirbution = tf.gather(inputs, [i for i in range(1,self.grid_size,2)], axis=1)\n",
    "            right_up_contirbution = tf.gather(right_up_contirbution, [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "            right_up_contirbution_additional_term = right_up_contirbution[:, :, :, 0, 0]\n",
    "            right_up_contirbution = right_up_contirbution[:,:,:,1,0]\n",
    "            ru_center_ = tf.gather(inputs, [i for i in range(1,self.grid_size,2)], axis=1)\n",
    "            ru_center_ = tf.gather(ru_center_, [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "            ru_center_ = ru_center_[:,:,:,1,1]\n",
    "            ru_contribution = -tf.expand_dims((right_up_contirbution_additional_term+\n",
    "                                               tf.multiply(right_up_contirbution,right_contributions_output) +\\\n",
    "                              tf.multiply(up_right_contribution,up_contributions_output))/ru_center_, -1)\n",
    "\n",
    "            up_left_contribution = tf.gather(inputs, idx, axis=1)\n",
    "            up_left_contribution = tf.gather(up_left_contribution, [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "            up_left_contribution = up_left_contribution[:, :, :, 2, 1]\n",
    "            left_up_contirbution = tf.gather(inputs, idx, axis=1)\n",
    "            left_up_contirbution = tf.gather(left_up_contirbution, [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "            left_up_contirbution_addtional_term = left_up_contirbution[:, :, :, 2, 0]\n",
    "            left_up_contirbution = left_up_contirbution[:, :, :, 1, 0]\n",
    "            lu_center_ = tf.gather(inputs, idx, axis=1)\n",
    "            lu_center_ = tf.gather(lu_center_, [i for i in range(1,self.grid_size,2)], axis=2)\n",
    "            lu_center_ = lu_center_[:, :, :, 1, 1]\n",
    "            lu_contribution = -tf.expand_dims((left_up_contirbution_addtional_term+\n",
    "                                               tf.multiply(up_left_contribution , up_contributions_output) + \\\n",
    "                               tf.multiply(left_up_contirbution , left_contributions_output)) / lu_center_, -1)\n",
    "\n",
    "            down_left_contribution = tf.gather(inputs, idx, axis=1)\n",
    "            down_left_contribution = tf.gather(down_left_contribution, idx, axis=2)\n",
    "            down_left_contribution = down_left_contribution[:, :, :, 2, 1]\n",
    "            left_down_contirbution = tf.gather(inputs, idx, axis=1)\n",
    "            left_down_contirbution = tf.gather(left_down_contirbution, idx, axis=2)\n",
    "            left_down_contirbution_additional_term = left_down_contirbution[:, :, :, 2, 2]\n",
    "            left_down_contirbution = left_down_contirbution[:, :, :, 1, 2]\n",
    "            ld_center_ = tf.gather(inputs, idx, axis=1)\n",
    "            ld_center_ = tf.gather(ld_center_, idx, axis=2)\n",
    "            ld_center_ = ld_center_[:, :, :, 1, 1]\n",
    "            ld_contribution = -tf.expand_dims((left_down_contirbution_additional_term+\n",
    "                                               tf.multiply(down_left_contribution , down_contributions_output) + \\\n",
    "                               tf.multiply(left_down_contirbution , left_contributions_output)) / ld_center_,-1)\n",
    "\n",
    "            down_right_contribution = tf.gather(inputs, [i for i in range(1,self.grid_size,2)], axis=1)\n",
    "            down_right_contribution = tf.gather(down_right_contribution, idx, axis=2)\n",
    "            down_right_contribution = down_right_contribution[:, :, :, 0, 1]\n",
    "            right_down_contirbution = tf.gather(inputs, [i for i in range(1,self.grid_size,2)], axis=1)\n",
    "            right_down_contirbution = tf.gather(right_down_contirbution, idx, axis=2)\n",
    "            right_down_contirbution_addtional_term = right_down_contirbution[:, :, :, 0, 2]\n",
    "            right_down_contirbution = right_down_contirbution[:, :, :, 1, 2]\n",
    "            rd_center_ = tf.gather(inputs, [i for i in range(1,self.grid_size,2)], axis=1)\n",
    "            rd_center_ = tf.gather(rd_center_, idx, axis=2)\n",
    "            rd_center_ = rd_center_[:, :, :, 1, 1]\n",
    "            rd_contribution = -tf.expand_dims((right_down_contirbution_addtional_term+tf.multiply(down_right_contribution , down_contributions_output) + \\\n",
    "                               tf.multiply(right_down_contirbution , right_contributions_output)) / rd_center_,-1)\n",
    "\n",
    "            first_row = tf.concat([ld_contribution, tf.expand_dims(left_contributions_output,-1),\n",
    "                                   lu_contribution], -1)\n",
    "            second_row = tf.concat([tf.expand_dims(down_contributions_output,-1),\n",
    "                                    tf.expand_dims(ones, -1), tf.expand_dims(up_contributions_output, -1)], -1)\n",
    "            third_row = tf.concat([rd_contribution, tf.expand_dims(right_contributions_output, -1),\n",
    "                                   ru_contribution], -1)\n",
    "\n",
    "            output = tf.stack([first_row, second_row, third_row], 0)\n",
    "            output = tf.transpose(output, (1, 2, 3, 0, 4))\n",
    "\n",
    "            return tf.to_complex128(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "926ad5c238a4420011e83b59655d6cd21b021d9ee1aa0438d38aa969cfe55744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
