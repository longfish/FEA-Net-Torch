{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:12:37.978677Z",
     "start_time": "2018-12-18T11:12:37.976016Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T11:10:53.160742Z",
     "start_time": "2018-12-30T11:10:51.404495Z"
    },
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEA_Net_h():\n",
    "    def __init__(self, data, cfg):\n",
    "        # set learning rate\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # data related\n",
    "        self.num_node = data['num_node']\n",
    "        self.E, self.mu, self.k, self.alpha = self.rho = data['rho'] #\n",
    "\n",
    "        # 3 dimensional in and out, defined on the nodes\n",
    "        self.load_pl = tf.placeholder(tf.float32, shape=(None, data['num_node'], data['num_node'], 3))\n",
    "        self.resp_pl = tf.placeholder(tf.float32, shape=(None, data['num_node'], data['num_node'], 3))\n",
    "\n",
    "        # get filters\n",
    "        self.get_w_matrix()\n",
    "        self.load_pred = self.forward_pass()\n",
    "\n",
    "\n",
    "    def get_w_matrix(self):\n",
    "        self.get_w_matrix_elast()\n",
    "        self.get_w_matrix_thermal()\n",
    "        self.get_w_matrix_coupling()\n",
    "        self.apply_physics_constrain(cfg)\n",
    "\n",
    "    def apply_physics_constrain(self, cfg):\n",
    "        # known physics\n",
    "        self.wtt_tf = tf.constant(self.wtt_ref)\n",
    "        self.wtx_tf = tf.constant(self.wtx_ref)\n",
    "        self.wty_tf = tf.constant(self.wty_ref)\n",
    "        self.wxt_tf = tf.constant(self.wxt_ref)\n",
    "        self.wyt_tf = tf.constant(self.wyt_ref)\n",
    "\n",
    "        # unknown physics\n",
    "        self.wxx_np = np.zeros_like(self.wxx_ref)\n",
    "        self.wyy_np = np.zeros_like(self.wyy_ref)\n",
    "        self.wxy_np = np.zeros_like(self.wxy_ref)\n",
    "        self.wyx_np = np.zeros_like(self.wyx_ref)\n",
    "\n",
    "        # TF variable vector\n",
    "        self.trainable_var_np = np.concatenate([self.wxx_np.flatten(),\n",
    "                                                self.wyy_np.flatten(),\n",
    "                                                self.wxy_np.flatten(),\n",
    "                                                self.wyx_np.flatten()],0)\n",
    "        self.trainable_var_pl = tf.placeholder(tf.float32, shape=(9*4,))\n",
    "\n",
    "        self.trainable_var_ref = np.concatenate([self.wxx_ref.flatten(),\n",
    "                                                 self.wyy_ref.flatten(),\n",
    "                                                 self.wxy_ref.flatten(),\n",
    "                                                 self.wyx_ref.flatten()], 0)\n",
    "\n",
    "        wxx_np, wyy_np, wxy_np, wyx_np = tf.split(self.trainable_var_pl,4)\n",
    "        self.wxx_tf = tf.reshape(wxx_np,(3,3,1,1))\n",
    "        self.wyy_tf = tf.reshape(wyy_np,(3,3,1,1))\n",
    "        self.wxy_tf = tf.reshape(wxy_np,(3,3,1,1))\n",
    "        self.wyx_tf = tf.reshape(wyx_np,(3,3,1,1))\n",
    "\n",
    "        # add constrains\n",
    "        self.singula_penalty = tf.abs(tf.reduce_sum(self.wxx_tf)) \\\n",
    "                               + tf.abs(tf.reduce_sum(self.wyy_tf)) \\\n",
    "                               + tf.abs(tf.reduce_sum(self.wxy_tf))\\\n",
    "                               + tf.abs(tf.reduce_sum(self.wyx_tf))\n",
    "        def get_sym_penalty(w):\n",
    "            return tf.abs(tf.reduce_sum((w[0,0,0,0]-w[2,2,0,0])**2)) \\\n",
    "                                +tf.abs(tf.reduce_sum((w[1,0,0,0]-w[1,2,0,0])**2)) \\\n",
    "                                +tf.abs(tf.reduce_sum((w[0,1,0,0]-w[2,1,0,0])**2)) \\\n",
    "                                +tf.abs(tf.reduce_sum((w[0,2,0,0]-w[2,0,0,0])**2))\n",
    "\n",
    "        self.symmetry_penalty = get_sym_penalty(self.wxx_tf)\\\n",
    "                               + get_sym_penalty(self.wyy_tf) \\\n",
    "                               + get_sym_penalty(self.wxy_tf)\\\n",
    "                               + get_sym_penalty(self.wyx_tf)\n",
    "\n",
    "        # self.E = tf.clip_by_value(self.E, 0, 1)\n",
    "        # self.mu = tf.clip_by_value(self.mu, 0, 0.5)\n",
    "\n",
    "        # tf.nn.conv2d filter shape: [filter_height, filter_width, in_channels, out_channels]\n",
    "        self.w_filter = tf.concat([tf.concat([self.wxx_tf, self.wxy_tf, self.wxt_tf],2),\n",
    "                                   tf.concat([self.wyx_tf, self.wyy_tf, self.wyt_tf],2),\n",
    "                                   tf.concat([self.wtx_tf, self.wty_tf, self.wtt_tf],2)],\n",
    "                                  3)\n",
    "\n",
    "    def get_w_matrix_coupling(self):\n",
    "        E, v = self.E, self.mu\n",
    "        alpha = self.alpha\n",
    "        self.wtx_ref = np.zeros((3,3,1,1), dtype='float32')\n",
    "        self.wty_ref = np.zeros((3,3,1,1), dtype='float32')\n",
    "        coef = E * alpha / (6*(v-1)) / 400 *1e6\n",
    "        self.wxt_ref = coef * np.asarray([[1, 0, -1],\n",
    "                                      [4, 0, -4],\n",
    "                                      [1, 0, -1]]\n",
    "                                     , dtype='float32').reshape(3,3,1,1)\n",
    "\n",
    "        self.wyt_ref = coef * np.asarray([[-1, -4, -1],\n",
    "                                      [0, 0, 0],\n",
    "                                      [1, 4, 1]]\n",
    "                                     , dtype='float32').reshape(3,3,1,1)\n",
    "\n",
    "    def get_w_matrix_thermal(self):\n",
    "        w = -1/3. * self.k * np.asarray([[1., 1., 1.], [1., -8., 1.], [1., 1., 1.]])\n",
    "        w = np.asarray(w, dtype='float32')\n",
    "        self.wtt_ref = w.reshape(3,3,1,1)\n",
    "\n",
    "    def get_w_matrix_elast(self):\n",
    "        E, mu = self.E, self.mu\n",
    "        cost_coef = E / 16. / (1 - mu ** 2)\n",
    "        wxx = cost_coef * np.asarray([\n",
    "            [-4 * (1 - mu / 3.), 16 * mu / 3., -4 * (1 - mu / 3.)],\n",
    "            [-8 * (1 + mu / 3.), 32. * (1 - mu / 3.), -8 * (1 + mu / 3.)],\n",
    "            [-4 * (1 - mu / 3.), 16 * mu / 3., -4 * (1 - mu / 3.)],\n",
    "        ], dtype='float32')\n",
    "\n",
    "        wxy = wyx = cost_coef * np.asarray([\n",
    "            [2 * (mu + 1), 0, -2 * (mu + 1)],\n",
    "            [0, 0, 0],\n",
    "            [-2 * (mu + 1), 0, 2 * (mu + 1)],\n",
    "        ], dtype='float32')\n",
    "\n",
    "        wyy = cost_coef * np.asarray([\n",
    "            [-4 * (1 - mu / 3.), -8 * (1 + mu / 3.), -4 * (1 - mu / 3.)],\n",
    "            [16 * mu / 3., 32. * (1 - mu / 3.), 16 * mu / 3.],\n",
    "            [-4 * (1 - mu / 3.), -8 * (1 + mu / 3.), -4 * (1 - mu / 3.)],\n",
    "        ], dtype='float32')\n",
    "\n",
    "        self.wxx_ref = wxx.reshape(3,3,1,1)\n",
    "        self.wxy_ref = wxy.reshape(3,3,1,1)\n",
    "        self.wyx_ref = wyx.reshape(3,3,1,1)\n",
    "        self.wyy_ref = wyy.reshape(3,3,1,1)\n",
    "\n",
    "    def boundary_padding(self,x):\n",
    "        ''' special symmetric boundary padding '''\n",
    "        left = x[:, :, 1:2, :]\n",
    "        right = x[:, :, -2:-1, :]\n",
    "        upper = tf.concat([x[:, 1:2, 1:2, :], x[:, 1:2, :, :], x[:, 1:2, -2:-1, :]], 2)\n",
    "        down = tf.concat([x[:, -2:-1, 1:2, :], x[:, -2:-1, :, :], x[:, -2:-1, -2:-1, :]], 2)\n",
    "        padded_x = tf.concat([left, x, right], 2)\n",
    "        padded_x = tf.concat([upper, padded_x, down], 1)\n",
    "        return padded_x\n",
    "\n",
    "    def forward_pass(self):\n",
    "        padded_resp = self.boundary_padding(self.resp_pl)  # for boundary consideration\n",
    "        wx = tf.nn.conv2d(input=padded_resp, filter=self.w_filter, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        return wx\n",
    "\n",
    "    def get_loss(self):\n",
    "        self.diff = self.load_pred - self.load_pl\n",
    "        self.diff_no_on_bc = self.diff[:,1:-1,1:-1,:]\n",
    "        self.l1_error = tf.reduce_mean(self.diff_no_on_bc**2)\n",
    "        self.loss = self.l1_error# + self.symmetry_penalty #+ self.singula_penalty\n",
    "        return self.loss\n",
    "\n",
    "    def get_grad(self):\n",
    "        self.rho_grads = tf.gradients(self.loss, self.trainable_var_pl)\n",
    "        return self.rho_grads\n",
    "\n",
    "    def get_hessian(self):\n",
    "        self.rho_hessian = tf.hessians(self.loss, self.trainable_var_pl)\n",
    "        return self.rho_hessian\n",
    "\n",
    "    # V2U mapping functions\n",
    "    def apply_bc(self, x):\n",
    "        x_bc = tf.pad(x[:, 1:-1, 1:-1, :], ((0,0), (1, 1),(1, 1), (0, 0)), \"constant\")  # for boundary consideration\n",
    "        return x_bc\n",
    "\n",
    "    def FEA_conv(self, w, x):\n",
    "        padded_input = self.boundary_padding(x)  # for boundary consideration\n",
    "        wx = tf.nn.conv2d(input=padded_input, filter=w, strides=[1, 1, 1, 1], padding='VALID')\n",
    "        wx_bc = wx * self.bc_mask # boundary_corrrect\n",
    "        return wx_bc\n",
    "\n",
    "    def v2u_layer(self, w, x):\n",
    "        wx = self.FEA_conv(w, x)\n",
    "        wx_bc = self.apply_bc(wx)\n",
    "        return wx_bc\n",
    "\n",
    "    def get_dmat(self):\n",
    "        d_matrix = tf.stack([self.wxx_tf[1,1,0,0], self.wyy_tf[1,1,0,0], 1])  # x, y, and t components\n",
    "        # d_matrix = tf.stack([self.wxx_tf[1,1,0,0], self.wyy_tf[1,1,0,0], self.wtt_tf[1,1,0,0]])  # x, y, and t components\n",
    "        return tf.reshape(d_matrix,(1,1,1,3))\n",
    "\n",
    "    def get_bc_mask(self):\n",
    "        bc_mask = np.ones_like(self.new_load)\n",
    "        bc_mask[:, 0, :, :] /= 2\n",
    "        bc_mask[:, -1, :, :] /= 2\n",
    "        bc_mask[:, :, 0, :] /= 2\n",
    "        bc_mask[:, :, -1, :] /= 2\n",
    "        return bc_mask\n",
    "\n",
    "    def init_solve(self, load, omega):\n",
    "        self.omega = omega\n",
    "        self.new_load = load\n",
    "        self.d_matrix = self.get_dmat()\n",
    "        self.bc_mask = self.get_bc_mask()\n",
    "        self.u_in = tf.placeholder(tf.float32, load.shape, name='u_in')\n",
    "        self.u_out = self.apply(self.u_in)\n",
    "\n",
    "    def apply(self, u_in):\n",
    "        wx = self.v2u_layer(self.w_filter, u_in)\n",
    "        u_out = self.omega * (self.new_load - wx) / self.d_matrix +  u_in\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, model, data, cfg):\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.cfg = cfg\n",
    "        self.init_w = np.zeros((3,3,1,1))\n",
    "\n",
    "        self.loss_value = None\n",
    "        self.grads_value = None\n",
    "\n",
    "        self.loss_tf = self.model.get_loss()\n",
    "        self.grad_tf = self.model.get_grad()\n",
    "        self.hessian_tf = self.model.get_hessian()\n",
    "        self.initial_graph()\n",
    "\n",
    "    def initial_graph(self):\n",
    "        # initialize\n",
    "        FLAGS = tf.app.flags.FLAGS\n",
    "        tfconfig = tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=True,\n",
    "        )\n",
    "        tfconfig.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=tfconfig)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def loss(self, w):\n",
    "        self.feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                          self.model.resp_pl: data['train_resp'],\n",
    "                          self.model.trainable_var_pl: w}\n",
    "        self.loss_value = self.sess.run(self.loss_tf, self.feed_dict).astype('float64')\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, w):\n",
    "        self.feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                          self.model.resp_pl: data['train_resp'],\n",
    "                          self.model.trainable_var_pl: w}\n",
    "        self.grads_value = self.sess.run(self.grad_tf, self.feed_dict)[0].flatten().astype('float64')\n",
    "        return self.grads_value\n",
    "\n",
    "    def hessian(self, w):\n",
    "        self.feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                          self.model.resp_pl: data['train_resp'],\n",
    "                          self.model.trainable_var_pl: w}\n",
    "        self.hessian_value = self.sess.run(self.hessian_tf, self.feed_dict)[0].astype('float64')\n",
    "        return self.hessian_value\n",
    "\n",
    "    def pred(self,w):\n",
    "        feed_dict = {self.model.load_pl: data['train_load'],\n",
    "                      self.model.resp_pl: data['train_resp'],\n",
    "                      self.model.trainable_var_pl: w.astype('float32')}\n",
    "        pred_value = self.sess.run(self.model.load_pred, feed_dict)\n",
    "        return pred_value\n",
    "\n",
    "    def run_BFGS(self):\n",
    "        from scipy.optimize import fmin_l_bfgs_b\n",
    "        x, min_val, info = fmin_l_bfgs_b(self.loss, self.init_w.flatten(),\n",
    "                                         fprime=self.grads, maxiter=200, maxfun=200,\n",
    "                                         disp= True)\n",
    "        print('    loss: {}'.format(min_val))\n",
    "        pass\n",
    "\n",
    "    def run_newton(self):\n",
    "        from scipy.optimize import minimize\n",
    "        self.result = minimize(self.loss, self.model.trainable_var_np, method=self.cfg['opt_method'],\n",
    "                          jac=self.grads, hess=self.hessian,\n",
    "                          options={'xtol': 1e-6, 'disp': True})\n",
    "        return self.result\n",
    "\n",
    "    def visualize(self, w):\n",
    "        pred_value = self.pred(w)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        idx = 0  # which data to visualize\n",
    "        for i in range(3):\n",
    "            plt.subplot(4, 3, i + 1)\n",
    "            plt.imshow(self.data['test_resp'][idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "            plt.subplot(4, 3, 3 + i + 1)\n",
    "            plt.imshow(self.data['test_load'][idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "            plt.subplot(4, 3, 6 + i + 1)\n",
    "            plt.imshow(pred_value[idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "            plt.subplot(4, 3, 9 + i + 1)\n",
    "            plt.imshow(self.data['test_load'][idx, 1:-1, 1:-1, i] - pred_value[idx, 1:-1, 1:-1, i])\n",
    "            plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    def est_rho(self, mat):\n",
    "        mat = mat.reshape(4,3,3)\n",
    "        mat[0]\n",
    "\n",
    "    def init_solve(self, load, omega=2/3.):\n",
    "        self.model.init_solve(load, omega)\n",
    "        self.solution = {'itr':[], 'loss': [], 'pred':[]}\n",
    "\n",
    "    def run_forward(self, filter, pred_i, resp_ref=None, max_itr=100):\n",
    "\n",
    "        st = 0 if self.solution['itr'] == [] else self.solution['itr'][-1]+10\n",
    "        for itr in tqdm(range(st, st+max_itr, 1)):\n",
    "            feed_dict = {self.model.u_in: pred_i, self.model.trainable_var_pl:filter}\n",
    "            pred_i = self.sess.run(self.model.u_out, feed_dict)\n",
    "            if itr%1 == 0:\n",
    "                self.solution['itr'] += [itr]\n",
    "                self.solution['pred'] += [pred_i]\n",
    "                if resp_ref is not None:\n",
    "                    pred_err_i = np.sqrt(np.sum((resp_ref - pred_i) ** 2)) / np.sqrt(  np.sum((resp_ref) ** 2))\n",
    "                    print(\"iter:{}  pred_err: {}\".format(itr, np.mean(pred_err_i)))\n",
    "                    self.solution['loss'] += [np.mean(pred_err_i)]\n",
    "\n",
    "        return pred_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(percent=None):\n",
    "    num_node = 37\n",
    "    # Purely thermal\n",
    "    # data = sio.loadmat('2D_thermoelastic_36by36_xy_fixed_single_data5.mat')\n",
    "\n",
    "    # purely structural\n",
    "    data = sio.loadmat('../data/elasticity/center_crack_36x36_xy.mat')\n",
    "\n",
    "    # coupled loading\n",
    "    #data = sio.loadmat('2D_thermoelastic_36by36_xy_fixed_single_data_half_loading.mat') \n",
    "\n",
    "    load = np.expand_dims(np.stack([-data['fx']/1e6, -data['fy']/1e6, data['ftem']], -1), 0).astype('float32')\n",
    "    resp = np.expand_dims(np.stack([data['ux']*1e6, data['uy']*1e6, data['utem']], -1), 0).astype('float32')\n",
    "    rho = [212/1e3, 0.288, 0., 0.] # E, mu, k, alpha\n",
    "\n",
    "    if percent is not None:\n",
    "        noise = percent * np.random.normal(size=load.shape)\n",
    "        loading_w_noise = (1+noise) * load\n",
    "        noise = percent * np.random.normal(size=load.shape)\n",
    "        response_w_noise = (1+noise) * resp\n",
    "\n",
    "    train_load = loading_w_noise\n",
    "    train_resp = response_w_noise\n",
    "    test_load = load\n",
    "    test_resp = resp\n",
    "    data = {'num_node': num_node,\n",
    "            'rho': rho,\n",
    "            'train_load': train_load,\n",
    "            'train_resp': train_resp,\n",
    "            'test_load': test_load,\n",
    "            'test_resp': test_resp,\n",
    "            }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "cfg = {'opt_method': 'Newton-CG', #'trust-ncg',#\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ftem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1039345/759735510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#snr=100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1039345/1158751429.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(percent)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#data = sio.loadmat('2D_thermoelastic_36by36_xy_fixed_single_data_half_loading.mat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ftem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ux'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m212\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# E, mu, k, alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ftem'"
     ]
    }
   ],
   "source": [
    "data = load_data(percent=0.001)#snr=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FEA_Net_h(data,cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model, data, cfg)\n",
    "result = evaluator.run_newton()#run_trust_ncg\n",
    "evaluator.visualize(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare computed filters results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computed filters (wxx, wyy, wxy, wyx):')\n",
    "for i in range(4):\n",
    "    mat = result.x[9*i:9*(i+1)]\n",
    "    print(mat.reshape(3,3))\n",
    "\n",
    "#evaluator.est_rho(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reference filters (wxx, wyy, wxy, wyx):')\n",
    "print(model.wxx_ref.reshape(3,3))\n",
    "print(model.wyy_ref.reshape(3,3))\n",
    "print(model.wxy_ref.reshape(3,3))\n",
    "print(model.wyx_ref.reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "evaluator.init_solve(load=data['test_load'], omega=2/3.)\n",
    "pred_i = np.zeros_like(data['test_resp'])  # data['test_resp']#\n",
    "resp_ref = data['test_resp']\n",
    "pred_i = evaluator.run_forward(model.trainable_var_ref, pred_i, resp_ref, max_itr=4000)\n",
    "s0 = evaluator.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# test the model\n",
    "evaluator.init_solve(load=data['test_load'], omega=2/3.)\n",
    "pred_i = np.zeros_like(data['test_resp'])  # data['test_resp']#\n",
    "pred_i = evaluator.run_forward(result.x, pred_i, resp_ref, max_itr=4000)\n",
    "s1 = evaluator.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(s0['itr'], s0['loss'], label='ref')\n",
    "plt.semilogy(s1['itr'], s1['loss'], label='pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "name": "main.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "67.7px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "584.933px",
    "left": "1px",
    "right": "2569px",
    "top": "111px",
    "width": "600px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
